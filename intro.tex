% \documentclass[manuscript.tex]{subfiles}
% \documentclass[12pt,a4paper]{report} %,openright,twoside
% \usepackage{thesisstyle}
% \addbibresource{bib/PhD.bib}
% % \setcounter{chapter}{1}
% \begin{document}

The subsurface continuation of exposed geology can be extrapolated and interpolated using structures mapped in surveys of the Earth's naturally occuring potential fields.
Potential field surveys offer low-cost investigations over a large spatial extent, and routinely used for geological mapping and interpretation \parencite{nabighian75thAnniversaryHistorical2005}.
For this reason, magnetic field surveys are commonly used by geophysicists for geological mapping and interpretation toward understanding the Earth in three dimensions.
Scattered surveys are widely used when interpolated to grid rasters, and interpreted individually or integrated with many other datasets for predicting the subsurface for processes such as numerical modelling and inversion.
In these tasks, the spatial resolution of the grid is a critical factor in their ability to define geological detail \parencite{islesGeologicalInterpretationAeromagnetic2018}.
The role of high-resolution details in these geophysical methods is becoming more important to exploration as resources are increasingly sought from below sedimentary cover.
Resolution enhancement for natural images has seen recent success from the use of deep learning \parencite{moserHitchhikerGuideSuperResolution2023}, however it is not understood if these methods could extend to geophysics data, which are highly distinct from the natural images used for training in prior enhancement methods.

\section{Research Aims}
The overall aim of this thesis is to adapt and extend the use of deep learning to improve the processing and enhancement and geophysics data. The three aims of this thesis are as follows:

\begin{itemize}
    \item{} Identifying how deep learning resolution enhancement methods previously developed for natural images are applicable to highly distinct magnetic potential fields data;

    \item{} Constructing a model framework to ensure example based models can be trained incorporating diverse types of geological features manifested in magnetic data, and evaluating the effectiveness of the framework with a resolution enhancement technique based on survey line spacing;

    \item{} Evaluating a method for representation learning of potential field survey point data, which can predict a grid directly from point located survey data, as well as grids of the directional derivatives calculated of the learnt function using an automatic differentiation framework.
\end{itemize}

The above aims are investigated using case studies with open access aeromagnetic data provided by Geoscience Australia.

\section{Aeromagnetic surveys}
\label{sec:introgeo}
Airborne surveys of the Earth's magnetic or gravitational potential fields are routinely acquired at a range of scales at different stages of exploration, from pre-competitive regional data to stimulate exploration \parencite{howardAirborneGeophysicalCoverage2004}, to targeted investigations by the exploration industry at the prospect scale of up to several square kilometres.
Surveys may also be collected on the ground, or less commonly in exploration, by ship or satellite, with most processing methods and interpretation shared between all forms of acquisition.
Aeromagnetic surveys are among the lowest cost geophysical method \parencite{dentithGeophysicsMineralExploration2014}, however the cost rapidly increases when surveying at higher resolution due to overheads in flight line sampling.
When acquiring data, aircraft fly straight transect lines at a safe elevation above topography, known as the topography drape.
Surveys are flown with a heading in which data will be acquired along line.
For regional and contemporary surveys this is recommended to be North-South, however early practice was to survey perpendicular to the dominant geological strike, under the expectation of sampling the greatest frequency of change in magnetic intensity \parencite{islesGeologicalInterpretationAeromagnetic2018}.
Higher frequencies within these data diminish with increasing source-sensor distance, therefore the lower the height, the more high-frequency components will be captured by the sensor.
Acquisition along flight lines is sampled at a rate of \qty{10}{\hertz} or greater, which corresponds to an interval of \qty{7}{\m} or shorter at nominal flight speeds of \qty{70}{\m\per\s} \parencite{goodwinAirborneMagneticRadiometric2023}.
The spacing between lines is a factor of the scale of investigation and the cost of acquisition, and regional pre-competitive data in Australia targets state-wide coverage at \qty{400}{\m}, which is generally regarded as the upper limit of usefulness to exploration \parencite{howardAirborneGeophysicalCoverage2004}.
These low-resolution surveys, funded by government geoscience agencies, are a key driver in greenfields exploration and are released as open file data.
Higher-resolution surveys over prospective areas fly lines at closer line spacings, of the order \qty{100}{\m}, in order to resolve greater detail.
The importance of these parameters in relation to resolvable detail will be outlined shortly.
The collected data may contain millions of samples scattered in three dimensions, and interpretation or processing often relies on regularisation to a quantised grid.

\subsection{Survey data regularisation}
\label{sec:introgrids}
Survey data can be interpreted as one dimensional transects, but more commonly they are regularised to a two-dimensional grid raster for interpretation in a process termed gridding.
The resulting interpolated array contains uniformly spaced nodes and is referred to as a grid.
Grids are raster data, where each pixel stores a scalar measurement of a specific property.
In geophysics and throughout this thesis, these are referred to as cells, and the property is a measure of the strength of the magnetic field at a specific location.
The field strength measured is the Total Magnetic Intensity (TMI), which is the vector sum of each directional vector of the potential \parencite{blakelyPotentialTheoryGravity1996}.
This scalar value is recorded in nanotesla (nT) and may be negative with an unbounded range that can exceed \qty{50000}{\nano\tesla} in the Earth's environment.
The location recorded at a sample point is the geographic latitude and longitude, and altitude, acquired with high-precision differential GPS, alongside radar altimeter elevation.
These data may be transformed to a flat projected system, where spatial dimensions are expressed in metres, used throughout this thesis.
There are numerous conventional gridding methods, and novel methods are frequently proposed in the literature.
The simplest use surrounding samples for interpolation, such as choosing the closest sample value or applying a transformation function to the neighbouring samples.
Of those most commonly used in potential field geophysics, these are minimum curvature \parencite{briggsMachineContouringUsing1974}, splines \parencite{bhattacharyyaBicubicSplineInterpolation1969,shureHarmonicSplinesGeomagnetic1982,smithGriddingContinuousCurvature1990}, and equivalent sources \parencite{dampneyEquivalentSourceTechnique1969, solerBetterStrategyInterpolating2020}.
Splines are used in bi-directional gridding, which is well-suited for aeromagnetic surveys, where the sample data are first interpolated in the line parallel direction, and the intermediate product is interpolated in the line-perpendicular direction \parencite{dentithGeophysicsMineralExploration2014}.
A method known as kriging is used in other areas of geoscience, such as geochemical mapping, and makes use of statistical properties of the known distribution \parencite{hansenInterpretiveGriddingAnisotropic1993,davis1986statistics}.
Some recently proposed gridding methods include the methods of \textcite{naprstekNewMethodInterpolating2019}, \textcite{xuGravityAnomalyReconstruction2019}, or \textcite{chenPotentialFieldData2022}.
Each interpolation method attempts to predict regularly spaced grids by leveraging properties intrinsic to the data, with the possible explicit integration of \emph{a priori} knowledge such as geophysical laws or geological context.
A review of spatial interpolation methods is provided in \textcite{liReviewComparativeStudies2011}.

\subsection{A definition for geophysical resolution}
In interpolated grids the spatial dimension of each cell is referred to as the cell size, with a unit of metre used in this thesis.
As previously stated, resolvable detail in geophysical surveys is a product of the distance between the causative magnetic body and sensor (height), and the line spacing \parencite{islesRelationshipsGeologicalResolution1992,islesGeologicalInterpretationAeromagnetic2018,dentithGeophysicsMineralExploration2014}.
Height is easily controlled by flying the lowest safe and sufficiently smooth topography drape, and along-line sampling is performed at a constant high rate, so the key factor controlling resolution in aeromagnetic survey design is the line spacing.
Further survey design considerations for airborne geophysics are outlined in \textcite{goodwinAirborneMagneticRadiometric2023,islesGeologicalInterpretationAeromagnetic2018,reidAeromagneticSurveyDesign1980}.
Each gridding method includes a final cell size parameter selectable by the geophysicist, with a long-standing guideline of one third to one fifth the line spacing.
This sufficiently preserves detail in areas of high sampling, while avoiding excessive interpolated cells in areas of low sampling, which may lead to artefacts.
Because of the sampling frequency of nominally \qty{7}{\m} in the flight line direction, and  up to \qty{400}{\m} in the line-perpendicular direction, the resulting grid resolution will be anisotropic at best, and uniformly low-resolution at worst.
An important property of sampled data is the Nyquist frequency, \[f_{Nyquist} = f_{sampling} / 2.\]
This is the lowest frequency at which a bandwidth limited signal may be sufficiently sampled, beyond which higher frequencies will be incorrectly recorded as aliasing.
An aliased signal contains spurious low-frequency features caused by the sampling, not the underlying signal.
This limiting frequency applies to each sampling direction in surveys, as well as the cell size of the grid.
The smallest resolvable feature in each of these can be spatially described by wavelength, as the inverse of frequency.
In low-resolution aeromagnetic surveys of \qty{400}{\m} line spacing, strong variations of magnetic intensity in the line-perpendicular direction  that occur over a distance shorter than \qty{800}{\m} will be aliased.
When gridded at \qty{80}{\m} cell size, the corresponding limit on resolvable detail is features as small as \qty{160}{\m}.
% This choice of cell size will effectively filter out features in the line-parallel direction that vary strongly, from those possibly present at \qty{14}{\m} through to \qty{160}{\m}.
Depending on the complexity of the geological domain, this may cause spatial aliasing in one direction.
This is visible in grids where features take on a blocky or stepped appearance, referred to as a beading artefact, or generally in this thesis as a low-resolution artefact.
Low-resolution gridded aeromagnetic data refers to surveys with a wide line spacing causing a lack of high-frequency details in the line-perpendicular direction, resulting in potential artefacts, and overly smooth or missing details in grid data.

Here, I state the definition of resolution adopted throughout this thesis.

\bigskip{}
\noindent{}\emph{Resolution in potential field geophysics refers to the level of geological detail in potential field grids.}
\bigskip{}

Resolution can be increased by:
\begin{enumerate}
    \item{} High frequencies, caused by geology, being present in the potential field,
    \item{} Capturing these high frequencies during surveying, by sampling at close line spacing and small source-sensor separation,
    \item{} Interpolating sample data with a small enough spatial cell size to preserve these frequencies.
\end{enumerate}

% - How are they used (geo interp, modelling, filtering) (detailed)
% levelling
% geological interpretation
% modelling
%

\subsection{Traditional methods for enhancing resolution}
As outlined in \Cref{sec:introgrids}, resolution is a product of sample distance and density, and gridded rasters have a specific number of cells in each axis depending on the spatial extent.
Upsampling raster data to larger height and width dimensions is commonplace, and generally performed by numerical image filters such as the cubic spline \parencite{keysCubicConvolutionInterpolation1981} or Lanczos filter \parencite{lanczos1988applied}.
Some of these interpolation methods are the basis of the gridding methods previously outlined, and simply selecting a smaller cell size during gridding is sufficient to achieve a larger image raster.
These filters are adept at imputing the required cell values while preserving the frequency content of the original raster.
However, no attempt is made at accurately increasing the high-frequency components of the raster, which are required by our definition for high-resolution geophysics.
Without sampling at a smaller separation or closer line spacing, it is still possible to increase the high-frequency content of aeromagnetic grids.

The rate at which the power of the component frequencies of the potential field diminish with increasing source-sensor distance is well known.
Back-calculation can be made to predict the power of these frequencies at a smaller separation, and this is termed downward continuation \textcite{bullardDeterminationMassesNecessary1948,blakelyPotentialTheoryGravity1996}.
The inverse calculation at a larger separation is termed upward continuation, and is useful for reducing potentially unwanted near-surface magnetic detail, or levelling data to a common datum (e.g.\ open file magnetic data in Australia are available levelled to the AWAGS datum \parencite{mintyAirborneGeophysicalMapping2011}).
Downward continuation offers the benefit of high-resolution data from low-resolution sampling, and is therefore highly studied \parencite{zuoDownwardContinuationTransformation2020,fediStableDownwardContinuation2002,zhangNumericalSolutionsMeanValue2018,guoPotentialFieldContinuation2020,gangImprovedStableDownward2018,pilkingtonPotentialFieldContinuation2017}.
However, due to the inclusion of sensor noise, the practicable limit of numerical methods is six times the low-resolution cell size.
Recent approaches in machine learning have overcome this limit, alongside alternative methods for enhancing aeromagnetic survey resolution.

\section{Geophysics and machine learning}
\label{sec:introdata}
% e.g. limited training data to deal with diverse geological features, geology various regionally - different potential fields features and range, etc....
Natural image raster data are ubiquitous in computer vision machine learning.
These are most commonly three channel arrays containing normalised brightness values in the red, green and blue channels.
Resolution in these rasters is typically a product of an imaging system or software defined grid with regular sampling.
Like in geophysics, these raster data have an array height and width, which is referred to as resolution.
However, the lack of spatial quantification for the size of natural images confuses the term with its definition for geophysical resolution.

Resulting from the processes described in \Cref{sec:introgrids}, geophysical rasters are highly distinct from the image data used widely in computer vision.
This includes the number of channels (3 in natural images, 1 in aeromagnetics), range (\qty{255} discrete values compared to \qty{50000} or more), and anisotropy of resolution.
Additionally, the features present within these data are highly dissimilar.
While natural images may contain common objects which share high-level features such as eyes, faces, or complex geometry, these data only share low-level features with aeromagnetic data, such as simple line and curve components.
This fact limits the applicability of transfer learning from methods in computer vision machine learning \parencite{tanSurveyDeepTransfer2018} to geoscience data.
These points also raise the uncertainty of methods developed for natural images to be  applicable to geoscience data.

Geoscience data faces a number of challenges distinct from natural images. These have been outlined in \textcite{karpatneMachineLearningGeosciences2019}, and relevant to this work are:
\begin{itemize}
    \item{} Spatio-Temporal Structure: Aeromagnetic grids are spatially corellated, neighbouring cells contain similar values arising from the same causative volume.
    \item{} Multi-Source Multi-Resolution Data: One location may be covered by multiple aeromagnetic surveys with different resolutions, or the same survey may be presented with different levels of processing.
    \item{} Poor Quality of Data: Sample data are subject to numerous sources of noise, which combine to become a significant fraction of the gridded data value, or be present as aliased frequencies.
    \item{} Small Sample Size: While total aeromagnetic coverage in Australia is high, the high-resolution extents are spatially limited and biased by geological domain.
\end{itemize}

Inference on real-world data presents many challenges \parencite{nikolenkoSyntheticDataDeep2021,tremblayTrainingDeepNetworks2018}.
Despite this, case studies are critical in promoting the adoption of applications in geophysics, by demonstrating a methods suitability to the data used within the task of interest.
As such, case studies are investigated for each aim within this thesis.

\subsection{Deep learning context}
Machine learning (ML) is a very broad family of techniques for learning functions from data.
Artificial neural networks are a subset of techniques in ML, inspired by a model of the biological neuron \parencite{bishopNeuralNetworksPattern1995}.
It has been established that if sufficient conditions are met, neural networks can approximate any function \parencite{hornikMultilayerFeedforwardNetworks1989}.
A mathematical model of a neuron forms the basis of these networks, and the number of neurons within the network and their arrangement are one primary descriptor of a neural network.
Neurons are paremeterised by a multiplicative weight term, an added bias term, and an activation function to scale the result.
Each neuron applies these operations to the input, which may either be the input data, or the output of earlier neurons.
The objective of training a neural network is to set the values for these for each neuron in the network, such that the trained network (or model) generalises to novel data.
This is performed by back propagation \parencite{rumelhartLearningRepresentationsBackpropagating1988}, a technique to navigate toward the lowest error solution by calculating the rate of improvement resulting from parameter updates.
A practical introduction to the practice of training machine learning is available from \textcite{stevensDeepLearningPyTorch2020}, while a more formal introduction is provided in \textcite{bishopPatternRecognitionMachine2006}.

The activation function performs scaling, but more importantly maps a range of input values to zero, which can be interpreted as the lack of a specific feature being present \parencite{williamsLogicActivationFunctions1986}.
For example, the rectified linear unit (ReLU) used in most tasks throughout this thesis maps negative input values to zero, and linearly for positive values.
Many activation functions have been proposed, and recent work on periodic activation functions such as the sinusoid \parencite{sitzmann2019siren} enable the networks used in \Cref{ch:paper3}.

The other primary descriptor of a neural network is its architecture, referring to the configuration of its intermediate layers between the input and output.
Key architectures used in this thesis are described below.
If the network architecture provides the capacity to store and retrieve learning, the data and training architecture provide the actual instruction and delivery.
There are broadly two classes of training; supervised and unsupervised learning.
The super-resolution and representation learning tasks in this thesis are both supervised tasks, where a reference is provided for the network to calculate an objective function of its performance on.
Unsupervised learning does not have a ground truth or target, and instead learns to identify patterns within the data for tasks in clustering, density estimation, and visualisation \parencite{bishopPatternRecognitionMachine2006}.

Deep learning is a field of contemporary machine learning, where multiple layers of feature learning are undertaken between the input to a method and the output.
The current generation of deep learning is reported by review articles to have begun in 2006 \parencite{dengDeepLearningMethods2014,goodfellowDeepLearning2016a}, and has pervaded many industries and research fields.
These review articles contain thorough background on the implementation and practice of various architectures for undertaking deep learning, as well as earlier machine learning or numerical models that can address tasks now approached with deep learning.
The deep learning tasks explored in this thesis are super-resolution (SR) for the objective of upsampling resolution enhancement, and implicit neural representation (INR).
The network architectures implemented in this thesis to address the tasks include convolutional neural networks (CNN), generative adversarial networks (GAN), and multilayer perceptrons (MLP).
A brief introduction to these topics is provided here.

In an image raster, neighbouring pixels define simple features, and these features combine in the wider image to define complex features.
A CNN is formed from stacked layers of small convolutional kernels, commonly in SR with the kernel size of \numproduct{3 x 3} cells.
While training, these low-level kernels learn simple functions, which are convolved with deeper layers to learn increasingly complex patterns across a larger image extent, while widening the receptive field.
CNN methods have long been well suited for raster data in computer vision tasks such as image classification \parencite[e.g.][]{simonyanVeryDeepConvolutional2015} and, more recently, resolution enhancement \parencite[e.g.][]{zhangResidualDenseNetwork2018}.
The earliest application of CNN to SR was demonstrated by \textcite{dongLearningDeepConvolutional2014}, where convolutional layers throughout the depth of a network are used for low-resolution patch extraction, feature mapping, and reconstruction of super-resolved images.
The outputs of each convolutional layer are similar to hand-crafted filters or the feature dictionaries in earlier example-based super-resolution methods \parencite{freemanExamplebasedSuperresolution2002}, but the learnt filters are more numerous and fully learned from the data with the deep learning approach.
Following the success of \parencite{dongLearningDeepConvolutional2014}, many iterative improvements have been made to CNN based SR\@.
These include SRCNN \parencite{dongImageSuperresolutionUsing2016}, RDN \parencite{zhangResidualDenseNetwork2018}, ESRGAN \parencite{wangESRGANEnhancedSuperresolution2018}, and others \parencite{ledigPhotorealisticSingleImage2017,limEnhancedDeepResidual2017}.
% While each of these works contribute unique features to CNN-based super-resolution, they follow a common stacked layer design.
% This comprises a set of initial input feature extraction convolutions, a sequence of convolutional blocks with activations (neurons), some number and arrangement of intermediate residual learning pathways (skip connections), and an upsampling block for feature upscaling and convolving latent features back to image space.
% Once trained, the learnt functions are conditioned to transform low-resolution features into high-resolution features, using the neighbouring input values of the low-resolution grid in the context of filters learnt from the training data.


Recently, CNNs have been surpassed by coordinate multilayer perceptron (CMLP) neural networks in some representation learning tasks, including SR \parencite{chenLearningContinuousImage2021}.
CMLPs specifically use a dataset containing individual input values corresponding to coordinate features, and train to predict individual output feature vectors at those coordinates \parencite[e.g.][]{mildenhallNeRFRepresentingScenes2020}.
Key to the performance of these networks are implicit functions, which parameterise a function learned from training dataset with a neural network analogue.
The network analogue can then be queried for information that fits the learnt function but was not included in the training data.
In this way, CMLP networks learn a signal as a function of its coordinates, and novel signal values can be predicted for coordinates in the continuous domain of the learnt function.

Generative Adversarial Networks \parencite{goodfellowGenerativeAdversarialNets2014} are a learning framework utilising two competing neural networks.
These are termed the generator and the discriminator, and can be any arbitrary networks linked by objective functions.
When best overall performance arises when each network is equally capable in its respective task, i.e.\ when the objective functions of each network are linked by the Nash equilibrium \parencite{salimansImprovedTechniquesTraining2016,lucicAreGANsCreated2018}.
Because the use of a discriminator allows an independent element for predictive capacity, GANs are highly suited for generative modelling, which includes the task of super-resolution.
However, it was considerably challenging to achieve a stable Nash equilibrium \parencite{salimansImprovedTechniquesTraining2016}, causing difficulty in training these networks, and to produce a diverse range of outputs.
Noise injection was later used in this framework as a method to drive diversity \parencite{karrasStylebasedGeneratorArchitecture2018,rakotonirinaESRGANFurtherImproving2020}.

%  introduce learning implicit representation from imagery and their application for imputation, I think it's useful to link this resolution improvement in geophysics as imputation problem.


\subsection{Machine learning in geoscience}
\label{sec:introgeoml}

Geoscience is a diverse field, with ubiquitous use of raster data.
Machine learning is not new to geoscience, and work has been performed on applications in the field for many years.
Recent reviews have highlighted a rapid increase in machine learning research contributions to Earth science.
The aims of this thesis are related to specific findings in these review articles.
\textcite{bergenMachineLearningDatadriven2019} recommends the development and use of benchmark datasets and identifies opportunities in the use of transfer learning from synthetic data.
This is echoed by \textcite{karpatneMachineLearningGeosciences2019}, who also identify prospective research avenues in theory guided science using physics-guided neural networks, the concept of directly leveraging \emph{a priori} domain knowledge within machine learning models.

Early adoption of SR was seen in satellite and airborne remote sensing, where the data share image features with natural images \parencite{lanarasSuperresolutionSentinel2Images2018,arunConvolutionalNetworkArchitectures2019,kawulokTrainingDeepNetworks2019}, and others.
Hyperspectral data SR are commonly investigated \parencite{yangHyperspectralImageClassification2018,arunCNNBasedSuperResolutionHyperspectral2020}.
Rock microscopy images have been upsampled with SR \parencite{niuInnovativeApplicationGenerative2020}, and their accuracy compared using domain specific parameter calculation.
SR with physics-informed learning has been performed by \textcite{bodeUsingPhysicsinformedEnhanced2021,jiangMeshfreeFlowNetPhysicsConstrainedDeep2020} in the field of fluid dynamics, \textcite{leongDeepBedMapDeepNeural2020} in the field of basement topography, and \textcite{jungbluthSingleframeSuperresolutionSolar2019} in astrophysics.
Additionally, physics-informed learning has been performed with multi-physics integration in \textcite{degen3DMultiphysicsUncertainty2022}.
Seismic data has been investigated with SR \parencite{liSuperresolutionSeismicVelocity2021}, and with the removal of noise \parencite{liDeepLearningSimultaneous2021}.

Various potential field gridding \parencite{naprstekApplicationsMachineLearning2019,wangDeepLearningGravity2019a} and downward continuation methods \parencite{liStableDownwardContinuation2023,yeHighprecisionDownwardContinuation2022} have been proposed leveraging neural networks.
Finally, in the recent topic of implicit representation there have been several applications proposed, including geological modelling \parencite{hillierGeoINRImplicitNeural2023}.

Beyond the applications investigated in this thesis, many other machine learning methods have been investigated in geoscience.
These include: clustering of geophysical textures \parencite{grujicGeophysicsNeuralNetworks2019}, prediction of geological map event history \parencite{guo3DGeologicalStructure2021}, automated interpretation of geological data \parencite{waldelandConvolutionalNeuralNetworks2018, babakhinSemisupervisedSegmentationSalt2019,dawsonImpactDatasetSize2023}, seismic data interpolation \parencite{wangDeeplearningbasedSeismicData2018}, and 3D structure, joint inversion, or modelling \parencite{guo3DGeologicalStructure2021,zhihouJointGravityGravity2021},

Additionally, deep learning methods in medical imaging and other scientific disciplines share challenges and modalities with geoscience raster data, including noise, small sample size, multi-source and multi-resolution, and other properties.
Advances in these fields can be explored and adapted in conjunction with work in geoscience.
Feature identification is a common theme in all fields, using deep learning to detect, classify, or segment features of interest to geoscience research.

These works in geoscience machine learning commonly reiterate the challenge of data acquisition.
One approach to overcoming this and other challenges faced in real-world geoscience data is to use synthetic data.
During this thesis, a large collection of synthetic data became available, containing realistic 3D geological voxel models and 2D geophysical forward models \parencite{jessellNoddyverseMassiveData2022}.
These data present a large amount of uniformly sampled and noise free grids from an unbiased set of geological domains, and may offer a solution to some of these data challenges.

\section{Research Contributions and Thesis Structure}
This thesis is presented as a series of papers which are published or in-preparation for publication.
These are presented in \Cref{ch:paper1,ch:paper2,ch:paper3}, each with a brief contextual introduction.
Key findings and summary conclusions of the research are discussed in \Cref{ch:conclusions}.

\Cref{ch:paper1} presents published work on an initial investigation into the technique of deep learning super-resolution for magnetic potential field data.
To our knowledge, this chapter presents the first investigation of deep learning super-resolution of gridded magnetic potential field data within the literature.
Two convolutional neural network models, namely RDN and ESRGAN+, from the contemporary literature are implemented \parencite{zhangResidualDenseNetwork2018,limEnhancedDeepResidual2017}.
With uncertainty on the amount of data required to train a SR model for magnetic grids, a dataset comprising readily available high- and low-resolution TMI grid pairs is formed using published state magnetic compilation maps of Western Australia \parencite{brett20MagneticMerged2020}.
These data contain magnetic features and textures from a range of geological domains.
The chapter concludes by observing the success of SR on magnetic features, characterising the performance of the two adapted networks, and recommending the method based on RDN as being more reliable for the SR task.
The primary contribution of \Cref{ch:paper1} is establishing the capacity of the SR networks developed for natural images in computer vision to extend to the distinctly different data of low-resolution aeromagnetic geophysics.

Following the findings of the previous chapter, \Cref{ch:paper2} addresses the need for more generalisable model training for real-world super-resolution.
It undertakes these aims by training a baseline synthetic model with data from a contemporaneously published collection of magnetic grids forward modelled from realistic geology \parencite{jessellNoddyverseMassiveData2022}, on data from over \num{300} distinct geological histories.
It subsequently fine-tune trains the baseline model on real-world high-resolution state magnetic data.
Furthermore, it adopts advances in the machine learning literature by implementing the LTE network \parencite{leeLocalTextureEstimator2022}.
The proposed method simulates aeromagnetic line sampling of a potential field extent at \qty{320}{\m} and \qty{80}{\m}, which are in the regional and prospect scale respectively.
While the baseline model can generalise to real-world data, some incorrect reconstructions remain.
By fine-tune training the model with transformed real-world state map data, these errors are rectified, and the structural accuracy is improved.

\Cref{ch:paper3} reports the use of coordinate multilayer perceptron (CMLP) neural networks for representation learning of a surveyed potential field extent.
With the proposed method, scattered line data can be encoded into the grid, and cells queried at interpolating coordinates to predict regularised grids.
CMLP networks are highly suited for processing spatial data such as point sampled geophysics surveys.
Additionally, spatial derivatives are calculated on the learnt function directly.
%TODO ensure refer back to aims
Both tasks are fundamental to interpretation and processing in geophysics, and by commencing the methods from point sample data, the number of individual processing steps is reduced, and the application is fully trainable.
To our knowledge, this research is the first description of deep learning implicit neural representation for aeromagnetic potential field data in the literature.

\Cref{ch:futurework} presents a synthesis discussion for the prior chapters. Given the recency of deep learning super-resolution and implicit neural representation, multiple avenues of future opportunities are identified.
These aim to increase the adoption of super-resolution in geophysics by addressing apprehension toward the reliability of interpretation of the outputs.
A synthesis comparison of the SR networks adapted in \Cref{ch:paper1,ch:paper2} is also presented, which prompts questions regarding model and dataset construction.
The use of \emph{a priori} information well understood to geophysics is also discussed, with potential application in both super-resolution and implicit neural representation.

Finally, overall conclusions are presented in \Cref{ch:conclusions}.

\printbibliography{}

% \end{document}