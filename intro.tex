% \documentclass[manuscript.tex]{subfiles}
% \documentclass[12pt,a4paper]{report} %,openright,twoside
% \usepackage{thesisstyle}
% \addbibresource{bib/PhD.bib}
% % \setcounter{chapter}{1}
% \begin{document}

The subsurface continuation of exposed geology can be extrapolated and interpolated using structures mapped in surveys of the Earth's naturally occurring potential fields.
Potential field surveys offer low-cost investigations over a large spatial extent, and are routinely used for geological mapping and interpretation \parencite{nabighian75thAnniversaryHistorical2005}.
For this reason, magnetic field surveys are commonly used by geophysicists for geological mapping and interpretation toward understanding the Earth in three dimensions.
Scattered surveys are commonly interpolated to grid rasters, and interpreted individually or integrated with other datasets for predicting the subsurface for processes such as numerical modelling and inversion.
In these tasks, the spatial resolution of the grid is a critical factor in their ability to define geological detail \parencite{islesGeologicalInterpretationAeromagnetic2013}.
The role of high-resolution details in these geophysical methods is becoming more important to exploration as resources are increasingly sought from below sedimentary cover.
Resolution enhancement for natural images has seen recent success from the use of deep learning \parencite{moserHitchhikerGuideSuperResolution2023}, however, it is not understood if these methods can extend to geophysics data, which differ significantly to the natural images used for training in prior enhancement methods.

\section{Research aims}
The overall aim of this thesis is to adapt and extend the use of deep learning to improve the processing and enhancement of potential field geophysics data. The three aims of this thesis are as follows:

\begin{itemize}
    \item{} Identify how deep learning resolution enhancement methods previously developed for natural images are applicable to highly distinct magnetic potential field data;

    \item{} Construct a model framework to ensure example-based models can be trained while incorporating diverse types of geological features manifested in magnetic data, and evaluate the effectiveness of the framework with a resolution enhancement technique based on survey line spacing;

    \item{} Evaluate a method for representation learning of potential field survey point data, which can predict a grid directly from point located survey data, as well as grids of the directional derivative of the learned function calculated using an automatic differentiation framework.
\end{itemize}

The above aims are investigated using case studies with open access aeromagnetic data provided by Geoscience Australia.

\section{Magnetic potential fields}
The Earth has a naturally occurring magnetic field, approximating a dipole oriented toward the top and bottom of the planet.
Several properties of the magnetic field are important to the machine learning methods in this thesis.
First, that a field refers to a set of functions of space and time.
The magnetic field is a vector field, with three orthogonal components.
Neural networks with sufficient parameters are recognised as universal function approximators \parencite{hornikMultilayerFeedforwardNetworks1989}, and should therefore be capable of approximating the functions of the magnetic field.
Second, the curl of the magnetic vector field is a force function known as the magnetic potential field \parencite{kelloggFoundationsPotentialTheory1967}.
The magnitude of the magnetic vector field is the total magnetic intensity (TMI) \parencite{blakelyPotentialTheoryGravity1996}, with the unit nanotesla (nT).

Magnetic surveys in exploration geophysics generally create TMI products, where TMI may be measured directly or calculated from measurements of each vector component.
To support various scientific endeavours, a model of this field is periodically constructed --- the International Geomagnetic Reference Field (IGRF).
The residual between the IGRF and measured TMI at a specific time and location is termed magnetic anomaly.
It may be negative, and can exceed several thousand nanotesla in the Earth's environment.

One of the key petrophysical properties influencing the magnetic anomaly is magnetic susceptibility, itself predominantly influenced by magnetite, a mineral commonly present across geological settings \parencite{clarkNotesRockMagnetization1991}.
Rocks may also be intrinsically magnetised with remnant magnetisation.
Because of these known petrophysical variations in rock magnetisation, surveys of the magnetic field can delineate and differentiate stratigraphic units and infer their composition.

\section{Aeromagnetic surveys}
\label{sec:introgeo}
Airborne surveys of the Earth's magnetic or gravitational potential fields are routinely acquired at a range of scales at different stages of exploration, from pre-competitive regional data to stimulate exploration \parencite{howardAirborneGeophysicalCoverage2004}, through to targeted investigations by the exploration industry at the prospect scale of up to several square kilometres.
Surveys may also be collected on the ground, or less commonly in exploration by ship or satellite, with most processing methods and interpretation shared between all forms of acquisition.
Aeromagnetic surveys are among the lowest cost geophysical method \parencite{dentithGeophysicsMineralExploration2014}.
Low-resolution regional surveys funded by government geoscience agencies are a key driver in greenfields exploration and are released as open file data.

There are many aspects of survey design controlling the resolvable detail within survey data.
When acquiring data, aircraft fly straight transect lines at a safe elevation above topography, known as the topography drape.
The power of higher frequencies in potential fields falls off with increasing source-sensor distance.
As such the lower the survey elevation, the more high-frequency components present in the potential field will be captured by the sensor.
Surveys are flown with a heading in which data will be acquired along line.
For regional and contemporary surveys this is recommended to be North-South, however, early practice was to survey perpendicular to the dominant geological strike, under the expectation of sampling the greatest frequency of change in magnetic intensity \parencite{islesGeologicalInterpretationAeromagnetic2013}.
Acquisition along flight lines is sampled at a rate of \qty{10}{\hertz} or greater, which corresponds to an interval of \qty{7}{\m} or shorter at nominal flight speeds of \qty{70}{\m\per\s} \parencite{goodwinAirborneMagneticRadiometric2023}.

The spacing between lines is a factor of the scale of investigation and the cost of acquisition, and regional pre-competitive data in Australia targets state-wide coverage at \qty{400}{\m}, which is generally regarded as the upper limit of usefulness to exploration \parencite{howardAirborneGeophysicalCoverage2004}.
Survey cost rapidly increases when surveying at higher resolution, due to overheads in flight line sampling.
Higher-resolution surveys over prospective areas fly lines at closer line spacings, of the order \qty{100}{\m}, in order to resolve greater detail.
The importance of these parameters in relation to resolvable detail will be outlined shortly.
The collected data may contain millions of samples scattered in three dimensions, and interpretation or processing often relies on regularisation to a quantised grid.

\subsection{Survey data regularisation}
\label{sec:introgrids}
Survey data can be interpreted as one-dimensional flight line transects, but more commonly they are regularised to a two-dimensional raster for interpretation, in a process termed gridding.
The resulting interpolated array contains uniformly spaced cells and is referred to as a grid.
Grids are raster data, where each pixel stores a scalar measurement of a specific property.
In the case of the aeromagnetic data used in this thesis, the property measured is TMI, and is processed to convey magnetic anomaly.
The location recorded at a sample point is the geographic latitude, longitude, and altitude, acquired with high-precision differential GPS, alongside radar altimeter elevation.
These data may be transformed to a projected coordinate system, where spatial dimensions are expressed in metres.

There are numerous conventional gridding methods, and novel methods are frequently proposed in the literature.
The simplest use the surrounding samples for interpolation, such as choosing the closest sample value or applying a transformation function to the neighbouring samples.
Of those most commonly used in potential field geophysics, these are minimum curvature \parencite{briggsMachineContouringUsing1974}, splines \parencite{bhattacharyyaBicubicSplineInterpolation1969,shureHarmonicSplinesGeomagnetic1982,smithGriddingContinuousCurvature1990}, and equivalent sources \parencite{dampneyEquivalentSourceTechnique1969, solerBetterStrategyInterpolating2020}.
Splines are used in bi-directional gridding, which is well-suited for aeromagnetic surveys, where the sample data are first interpolated in the line-parallel direction, and the intermediate product is interpolated in the line-perpendicular direction \parencite{dentithGeophysicsMineralExploration2014}.
A method known as kriging is used in other areas of geoscience, such as geochemical mapping, and makes use of statistical properties of the known distribution \parencite{hansenInterpretiveGriddingAnisotropic1993,davis1986statistics}.
A review of established spatial interpolation methods is provided in \textcite{liReviewComparativeStudies2011}.
More recently proposed gridding methods include the methods of \textcite{naprstekNewMethodInterpolating2019}, \textcite{xuGravityAnomalyReconstruction2019}, or \textcite{chenPotentialFieldData2022}.
Each interpolation method attempts to predict regularly spaced grids by leveraging properties intrinsic to the data, with the possible explicit integration of \emph{a priori} knowledge such as geophysical laws or geological context.

\subsection{A definition for geophysical resolution}
In interpolated grids the spatial dimension of each cell is referred to as the cell size.
As previously stated, resolvable detail in geophysical surveys is a product of the height between the causative magnetic body and the sensor, and the line spacing \parencite{islesRelationshipsGeologicalResolution1992,islesGeologicalInterpretationAeromagnetic2013,dentithGeophysicsMineralExploration2014}.
Height is controlled by flying the lowest safe and sufficiently smooth topography drape, and along-line sampling is performed at a constant high rate, so the key factor controlling resolution in aeromagnetic survey design is the line spacing.
Further survey design considerations for airborne geophysics are outlined in \textcite{goodwinAirborneMagneticRadiometric2023,islesGeologicalInterpretationAeromagnetic2013,reidAeromagneticSurveyDesign1980}.
Each gridding method includes a final cell size parameter selectable by the geophysicist, with a long-standing guideline of being one third to one fifth the line spacing.
This sufficiently preserves detail in areas of high sampling, while avoiding excessive interpolated cells in areas of low sampling, which may lead to artefacts and misrepresentation of the measured field.

% If the sampling frequency is nominally \qty{7}{\m} in the flight line direction, and up to \qty{400}{\m} in the line-perpendicular direction, the resulting grid resolution will be anisotropic at best, and uniformly low-resolution at worst.
An important property of sampled data is the Nyquist frequency, \[f_{Nyquist} = f_{sampling} / 2.\]
This is the lowest frequency \(f\) at which a bandwidth limited signal may be sufficiently sampled, below which higher frequencies will be incorrectly recorded as aliasing.
An aliased signal contains spurious features not present in the original signal.
A Nyquist frequency applies to each sampling axis in surveys, as well as to the spacing of cells in the output grid.
The smallest resolvable feature in each of these can be spatially described by wavelength, as the inverse of Nyquist frequency.
For example, in low-resolution aeromagnetic surveys with \qty{400}{\m} line spacing, rapid variations of magnetic intensity in the line-perpendicular direction that occur over a distance shorter than \qty{800}{\m} will be aliased.
When gridded at \qty{80}{\m} cell size, the smallest accurately resolvable detail is \qty{160}{\m}.
% This choice of cell size will effectively filter out features in the line-parallel direction that vary strongly, from those possibly present at \qty{14}{\m} through to \qty{160}{\m}.
Depending on the complexity of the geological domain, this may cause spatial aliasing in one direction.
This is visible in grids where features take on a blocky or stepped appearance, referred to as  beading, or generally in this thesis, as a low-resolution artefact.
Low-resolution gridded aeromagnetic data refers to surveys with a wide line spacing causing a lack of high-frequency details in the line-perpendicular direction, resulting in potential artefacts, and overly smooth or missing details in grid data.

The following definition of geophysical resolution is adopted throughout this thesis:

\bigskip{}
\noindent{}\emph{Resolution refers to the smallest possible geological detail observable in potential field data. High-resolution refers to high frequencies, caused by geology, being represented in the sampled field.}

\bigskip{}
Resolution in geophysical grids can be increased by:
\begin{enumerate}
    \item{} Capturing these high frequencies during surveying, by sampling at close line spacing and small source-sensor separation,
    \item{} Interpolating sample data with a small enough spatial cell size to preserve these frequencies.
\end{enumerate}

% - How are they used (geo interp, modelling, filtering) (detailed)
% levelling
% geological interpretation
% modelling
%

\subsection{Traditional methods for enhancing resolution}
As outlined in \Cref{sec:introgrids}, geophysical resolution is a product of sample distance and sampling density, and gridded rasters have a specific number of cells in each axis depending on the spatial extent.
Upsampling raster data to greater cell counts in the height and width dimensions by interpolation is commonplace, and often described as an increase in resolution, however no attempt is made by these operations to increase geophysical resolution.
Upsampling is generally performed by numerical image filters such as the cubic spline \parencite{keysCubicConvolutionInterpolation1981} or Lanczos filter \parencite{lanczos1988applied}.
Some of these interpolation methods are the basis of the gridding methods previously outlined, and simply selecting a smaller cell size during gridding is sufficient to achieve a larger image raster.
These filters are adept at imputing the required cell values while preserving the frequency content of the original raster.
However, without the inclusion of new or supporting information such as additional sampling, supporting datasets, or other \emph{a priori}, no reasonable attempt can be made to increase geophysical resolution.

Using known physical properties of the potential field, is possible to increase the high-frequency content of aeromagnetic grids.
The rate at which the power of the component frequencies of the potential field diminish with increasing source-sensor distance is well known.
Back-calculation can be made to predict the power of these frequencies at a smaller separation, and this is termed downward continuation \parencite{bullardDeterminationMassesNecessary1948,blakelyPotentialTheoryGravity1996}.
The inverse calculation at a larger separation is termed upward continuation, and is useful for reducing potentially unwanted near-surface magnetic detail, or levelling data to a common datum (e.g.\ open file magnetic data in Australia are available levelled to the AWAGS datum \parencite{mintyAirborneGeophysicalMapping2011}).
Downward continuation offers the benefit of high-resolution data from low-resolution sampling, and is therefore highly studied \parencite{zuoDownwardContinuationTransformation2020,fediStableDownwardContinuation2002,zhangNumericalSolutionsMeanValue2018,guoPotentialFieldContinuation2020,gangImprovedStableDownward2018,pilkingtonPotentialFieldContinuation2017}.
However, due to the inclusion of sensor noise, the practicable limit of numerical methods is six times the low-resolution cell size.
Recent approaches in machine learning have overcome this limit, alongside alternative methods for enhancing aeromagnetic survey resolution.

\section{Geophysics and machine learning}
\label{sec:introdata}
% e.g. limited training data to deal with diverse geological features, geology various regionally - different potential fields features and range, etc....
Natural image raster data are ubiquitous in computer vision machine learning.
These are most commonly three channel arrays containing normalised brightness values in the red, green and blue channels.
Resolution in these rasters is typically a product of an imaging system or software defined grid with regular sampling.
Like in geophysics, these raster data have an array height and width, which is referred to as resolution.
However, the lack of spatial quantification for the pixel size of natural images confuses the term with its use in geophysical resolution.

Resulting from the processes described in \Cref{sec:introgrids}, geophysical rasters are distinct from the image data used widely in computer vision.
This includes the number of channels (3 in natural images, 1 in aeromagnetics), range (\qty{255} discrete values compared to \qty{50000} or more), and anisotropy of resolution.
Additionally, the features present within these data are highly dissimilar.
While natural images may contain common objects which share high-level features such as eyes, faces, or the built environment, these data only share low-level features with aeromagnetic data, such as simple line and curve components.
This fact limits the applicability of transfer learning from methods in computer vision machine learning \parencite{tanSurveyDeepTransfer2018} to geoscience data.
These points also raise the uncertainty of methods developed for natural images to be  applicable to geoscience data.

Geoscience data faces a number of challenges distinct from natural image data. These have been outlined in \textcite{karpatneMachineLearningGeosciences2019}, and relevant to this work are:
\begin{itemize}
    \item{} Spatio-temporal structure: Aeromagnetic grids are spatially correlated, neighbouring cells contain similar values arising from the same causative volume.
    \item{} Multi-source multi-resolution data: One location may be covered by multiple aeromagnetic surveys with different resolutions, or the same survey may be presented with different levels of processing.
    \item{} Poor quality of data: Sample data are subject to numerous sources of noise, which combine to become a significant fraction of the gridded data value, or be present as aliased frequencies.
    \item{} Small sample size: While total aeromagnetic coverage in Australia is high, the high-resolution extents are spatially limited and biased by geological domain.
\end{itemize}

Inference on real-world data presents many challenges \parencite{nikolenkoSyntheticDataDeep2021,tremblayTrainingDeepNetworks2018}.
Despite this, case studies are critical in promoting the adoption of applications in geophysics, by demonstrating a method's suitability to the data used within the task of interest.
As such, case studies are investigated for each aim within this thesis.

\subsection{Deep learning context}
Machine learning (ML) is a broad family of techniques for learning from data.
Artificial neural networks are a subset of techniques in ML, inspired by a model of the biological neuron \parencite{bishopNeuralNetworksPattern1995}.
It has been established that if sufficient conditions are met, neural networks can approximate any function \parencite{hornikMultilayerFeedforwardNetworks1989}.
A mathematical model of a neuron forms the basis of these networks, and the number of neurons within the network and their arrangement are one primary descriptor of a neural network.
Neurons are parameterised by a multiplicative weight term, an additive bias term, and an activation function which transforms the result.
Each neuron applies these operations to the input, which may either be the input data, or the output of earlier neurons.
The objective of training a neural network is to set the parameters for each neuron in the network, such that the trained network (or model) generalises to novel data.
This is performed by back propagation \parencite{rumelhartLearningRepresentationsBackpropagating1988}, a technique to navigate toward the lowest error solution by calculating the rate of improvement resulting from parameter updates.
A practical introduction to the practice of training machine learning is available in \textcite{stevensDeepLearningPyTorch2020}, while a more formal introduction is provided in \textcite{bishopPatternRecognitionMachine2006}.

The activation function performs a non-linear transformation, and importantly, maps a range of input values to zero, which can be interpreted as the lack of a specific feature being present \parencite{williamsLogicActivationFunctions1986}.
For example, the rectified linear unit (ReLU) used in most tasks throughout this thesis maps negative input values to zero, and linearly for positive values.
Many activation functions have been proposed, and recent work on periodic activation functions such as the sinusoid \parencite{sitzmann2019siren} enable the networks used in \Cref{ch:paper3}.

The other primary descriptor of a neural network is its architecture, referring to the configuration of its intermediate layers between the input and output.
% If the network architecture provides the capacity to store and retrieve learning, the data and training architecture provide the actual instruction and mode of delivery.
The input and output layer configuration is dependent on the dimensionality of the data, but the parameters of the intermediate layers are constrained only by computational resources.
In addition to the shape and count of the intermediate layers, the style of connection between individual neurons is fundamental to the architecture. 
These connection styles and their application within this thesis are described below.

The second key determinant of a Neural Network is the training.
There are broadly two classes of training: supervised and unsupervised learning.
The super-resolution and representation learning tasks in this thesis are both supervised tasks, where a reference is provided for the network to calculate an objective loss function of its performance.
Unsupervised learning does not have a ground truth or target, and instead learns to identify patterns within the data for tasks in clustering, density estimation, and visualisation \parencite{bishopPatternRecognitionMachine2006}.

Deep learning is a field of contemporary machine learning, where multiple layers of feature learning are undertaken between the input to a method and the output.
The current generation of deep learning is reported by review articles to have begun in 2006 \parencite{dengDeepLearningMethods2014,goodfellowDeepLearning2016a}, and has pervaded many industries and research fields.
These review articles contain thorough background on the implementation and practice of various architectures for undertaking deep learning, as well as earlier machine learning or numerical models that can address tasks now approached with deep learning.
The deep learning tasks explored in this thesis are super-resolution (SR) for the objective of upsampling resolution enhancement, and implicit neural representation (INR).
The network architectures implemented in this thesis to address the tasks include convolutional neural networks (CNN), generative adversarial networks (GAN), and multilayer perceptrons (MLP).
A brief introduction to these topics is provided here.

In an image raster, neighbouring pixels define simple features, and these features combine in the wider image to define complex features.
A CNN is formed from stacked layers of small convolutional kernels, commonly in SR with the kernel size of \numproduct{3 x 3} cells.
While training, these low-level kernels learn simple functions, which are convolved with deeper layers to learn increasingly complex patterns across a larger image extent, while widening the receptive field.
CNN methods have long been well suited for raster data in computer vision tasks such as image classification \parencite[e.g.][]{simonyanVeryDeepConvolutional2015} and, more recently, resolution enhancement \parencite[e.g.][]{zhangResidualDenseNetwork2018}.
The earliest application of CNN to SR was demonstrated by \textcite{dongLearningDeepConvolutional2014}, where convolutional layers throughout the depth of a network are used for low-resolution patch extraction, feature mapping, and reconstruction of super-resolved images.
The outputs of each convolutional layer are similar to hand-crafted filters or the feature dictionaries in earlier example-based super-resolution methods \parencite{freemanExamplebasedSuperresolution2002}, but the learned filters are more numerous and fully learned from the data with the deep learning approach.
Following the success of \parencite{dongLearningDeepConvolutional2014}, many iterative improvements have been made to CNN based SR\@.
These include SRCNN \parencite{dongImageSuperresolutionUsing2016}, RDN \parencite{zhangResidualDenseNetwork2018}, ESRGAN \parencite{wangESRGANEnhancedSuperresolution2018}, and others \parencite{ledigPhotorealisticSingleImage2017,limEnhancedDeepResidual2017}.
% While each of these works contribute unique features to CNN-based super-resolution, they follow a common stacked layer design.
% This comprises a set of initial input feature extraction convolutions, a sequence of convolutional blocks with activations (neurons), some number and arrangement of intermediate residual learning pathways (skip connections), and an upsampling block for feature upscaling and convolving latent features back to image space.
% Once trained, the learned functions are conditioned to transform low-resolution features into high-resolution features, using the neighbouring input values of the low-resolution grid in the context of filters learned from the training data.

Recently, CNNs have been surpassed by coordinate multilayer perceptron (CMLP) neural networks in some representation learning tasks, including SR \parencite{chenLearningContinuousImage2021}.
CMLPs specifically use a dataset containing individual input values corresponding to coordinate features, and train to predict individual output feature vectors at those coordinates \parencite[e.g.][]{mildenhallNERFRepresentingScenes2020}.
Key to the performance of these networks are implicit functions, which parameterise a function learned from training dataset with a neural network analogue.
The network analogue can then be queried for information that fits the learned function but was not included in the training data.
In this way, CMLP networks learn a signal as a function of its coordinates, and novel signal values can be predicted for coordinates in the continuous domain of the learned function.

Generative Adversarial Networks \parencite{goodfellowGenerativeAdversarialNets2014} are a learning framework utilising two competing neural networks.
These are termed the generator and the discriminator, and can be any arbitrary networks linked by an objective function.
The GAN architecture relies on each network gaining capability in its respective task, and informing the objective function of the other.
These objective functions are linked by the Nash equilibrium \parencite{salimansImprovedTechniquesTraining2016,lucicAreGANsCreated2018}.
Because the use of a discriminator allows an independent element for predictive capacity, GANs are highly suited for generative modelling, which includes the task of super-resolution.
However, it was considerably challenging to achieve a stable Nash equilibrium \parencite{salimansImprovedTechniquesTraining2016}, causing difficulty in training these networks, and to produce a diverse range of outputs.
Noise injection was later used in this framework as a method to drive diversity \parencite{karrasStylebasedGeneratorArchitecture2018,rakotonirinaESRGANFurtherImproving2020}.

%  introduce learning implicit representation from imagery and their application for imputation, I think it's useful to link this resolution improvement in geophysics as imputation problem.


\subsection{Machine learning in geoscience}
\label{sec:introgeoml}

Geoscience is a diverse field, with ubiquitous use of raster data.
Machine learning is not new to geoscience, and work has been performed on applications in the field for many years.
Recent reviews have highlighted a rapid increase in machine learning research contributions to Earth science, and the aims of this thesis are related to specific findings in these review articles.
\textcite{bergenMachineLearningDatadriven2019} recommends the development and use of benchmark datasets and identifies opportunities in the use of transfer learning from synthetic data.
This is echoed by \textcite{karpatneMachineLearningGeosciences2019}, who also identify prospective research avenues in theory guided science using physics-guided neural networks, the concept of directly leveraging \emph{a priori} domain knowledge within machine learning models.

Early adoption of SR was seen in satellite and airborne remote sensing, where the data share image features with natural images \parencite{lanarasSuperresolutionSentinel2Images2018,arunConvolutionalNetworkArchitectures2019,kawulokTrainingDeepNetworks2019}, and others.
Hyperspectral data SR are commonly investigated \parencite{yangHyperspectralImageClassification2018,arunCNNBasedSuperResolutionHyperspectral2020}.
Rock microscopy images have been upsampled with SR \parencite{niuInnovativeApplicationGenerative2020}, and their accuracy compared using domain specific parameter calculation.
SR with physics-informed learning has been performed by \textcite{bodeUsingPhysicsinformedEnhanced2021,jiangMeshfreeFlowNetPhysicsconstrainedDeep2020} in the field of fluid dynamics, \textcite{leongDeepBedMapDeepNeural2020} in the field of basement topography, and \textcite{jungbluthSingleframeSuperresolutionSolar2019} in astrophysics.
Additionally, physics-informed learning has been performed with multi-physics integration in \textcite{degen3DMultiphysicsUncertainty2022}.
Seismic data has been investigated with SR \parencite{liSuperresolutionSeismicVelocity2021}, and SR with the removal of noise \parencite{liDeepLearningSimultaneous2021}.

Various potential field gridding \parencite{naprstekNewMethodInterpolating2019, wangDeepLearningGravity2019a} and downward continuation methods \parencite{liStableDownwardContinuation2023,yeHighprecisionDownwardContinuation2022} have been proposed leveraging neural networks.
Finally, in the recent topic of implicit representation there have been several applications proposed, including geological modelling \parencite{hillierGeoINRImplicitNeural2023}.

Beyond the applications investigated in this thesis, many other machine learning methods have been investigated in geoscience.
These include: clustering of geophysical textures \parencite{grujicGeophysicsNeuralNetworks2019}, prediction of geological map event history \parencite{guo3DGeologicalStructure2021}, automated interpretation of geological data \parencite{waldelandConvolutionalNeuralNetworks2018, babakhinSemisupervisedSegmentationSalt2019,dawsonImpactDatasetSize2023}, seismic data interpolation \parencite{wangDeeplearningbasedSeismicData2018}, and 3D structure, joint inversion, or modelling \parencite{guo3DGeologicalStructure2021}.

Additionally, deep learning methods in medical imaging and other scientific disciplines share challenges and modalities with geoscience raster data, including noise, small sample size, multi-source and multi-resolution, and other properties.
Advances in these fields can be explored and adapted in conjunction with work in geoscience.
Feature identification is a common theme in all fields, using deep learning to detect, classify, or segment features of interest to geoscience research.

These works in geoscience machine learning commonly reiterate the challenge of data acquisition.
One approach to overcoming this and other challenges faced in real-world geoscience data is to use synthetic data.
During this thesis, a large collection of synthetic data became available, containing realistic 3D geological voxel models and 2D geophysical forward models \parencite{jessellNoddyverseMassiveData2022}.
These data present a large amount of uniformly sampled and noise-free grids from an unbiased set of geological domains, and may offer a solution to some of these data challenges.

\section{Research contributions and thesis structure}
This thesis is presented as a series of papers which are published or in-preparation for publication.
These are presented in \Cref{ch:paper1,ch:paper2,ch:paper3}, with identification of opportunities for future work described in \Cref{ch:futurework}.
Key findings and summary conclusions of the research are discussed in \Cref{ch:conclusions}.

\Cref{ch:paper1} presents published work on an initial investigation into the technique of deep learning super-resolution for magnetic potential field data.
To our knowledge, this chapter presents the first investigation of deep learning super-resolution of gridded magnetic potential field data within the literature.
Two convolutional neural network models, namely RDN and ESRGAN+ \parencite{zhangResidualDenseNetwork2018,limEnhancedDeepResidual2017}, are adapted to suit geophysical data.
With uncertainty on the amount of data required to train a SR model for magnetic grids, a dataset comprising readily available high- and low-resolution TMI grid pairs is formed using published state magnetic compilation maps of Western Australia \parencite{brett20MagneticMerged2020}.
These data contain magnetic features and textures from a range of geological domains.
The chapter concludes by observing the success of SR on magnetic features, characterising the performance of the two adapted networks, and recommending the method based on RDN as being more reliable for the SR task.
The primary contribution of \Cref{ch:paper1} is establishing the capacity of the SR networks developed for natural images in computer vision to extend to the distinctly different data of low-resolution aeromagnetic geophysics.

Following the findings of the previous chapter, \Cref{ch:paper2} addresses the need for more generalisable model training for real-world super-resolution.
It undertakes these aims by training a baseline synthetic model with data from a contemporaneously published collection of magnetic grids forward modelled from realistic geology \parencite{jessellNoddyverseMassiveData2022}, on data from over \num{300} distinct geological histories.
It subsequently fine-tune trains the baseline model on real-world high-resolution state magnetic data.
Furthermore, it adopts advances in the machine learning literature by adapting the LTE network \parencite{leeLocalTextureEstimator2022} for the geophysical task.
The proposed method simulates aeromagnetic line sampling of a potential field extent at \qty{320}{\m} and \qty{80}{\m}, which are in the regional and prospect scales respectively.
While the baseline model can generalise to real-world data, some incorrect reconstructions remain.
By fine-tune training the model with real-world state map data, these errors are rectified, and the structural accuracy is improved.

\Cref{ch:paper3} reports the use of coordinate multilayer perceptron (CMLP) neural networks for implicit neural representation (INR) of a surveyed potential field extent.
With the proposed method, scattered line data can be encoded into a neural network model, and grids are created by querying cells at regular coordinates.
% CMLP networks are highly suited for processing spatial data such as point sampled geophysics surveys.
Additionally, spatial derivatives are calculated on the learned function directly.
%TODO ensure refer back to aims
Both tasks are fundamental to interpretation and processing in geophysics, and by commencing the methods from point sample data, the number of individual processing steps is reduced, and the application is fully trainable.
To our knowledge, this research is the first of its kind in geophysical literature.

\Cref{ch:futurework} presents a synthesis discussion for the prior chapters.
Given the recency of deep learning super-resolution and implicit neural representation for geoscience, multiple avenues of future opportunities are identified.
These include characterising the practice of super-resolution, and approaches to further enhancement of the methods presented in this thesis.
% These aim to increase the adoption of super-resolution in geophysics by addressing apprehension toward the reliability of interpretation of the outputs.
A synthesis comparison of the SR networks adapted in \Cref{ch:paper1,ch:paper2} is also presented, which prompts questions regarding model and dataset construction.
The use of \emph{a priori} information well understood to geophysics is also discussed, with potential application in both super-resolution and implicit neural representation.

Finally, overall conclusions are presented in \Cref{ch:conclusions}.

% \printbibliography{}

% \end{document}